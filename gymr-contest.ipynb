{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym Retro\n",
    "\n",
    "[Gym Retro](https://blog.openai.com/gym-retro/) is a platform for [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) research on games. It turns out that old games are a perfect fit for benchmarking and improving RL agents in a simulated environment. After two years after the beta release of [Gym](https://blog.openai.com/openai-gym-beta/), OpenAI released an extension of this amazing software by adding more game environments. The goal of the new platform is to study the ability of the agents to *generalize* between games with similar concepts but different appearances.\n",
    "\n",
    "![retro-gif](https://github.com/floydhub/gym-retro-template/raw/master/images/retro.gif)\n",
    "\n",
    "## Gym Retro Contest - Sonic The Hedgehog‚Ñ¢\n",
    "\n",
    "[In this contest](https://blog.openai.com/retro-contest/), participants try to create the best agent for playing custom levels of the Sonic games ‚Äî without having access to those levels during development. You can find more detail in this [page](https://contest.openai.com/details).\n",
    "\n",
    "As mentioned in the contest's description this is a Transfer Learning task, which means that you are free to train your agent however you'd like, however, the OpenAI Team recommend using Sonic 1, 2, and 3 & Knuckles, which are available on Steam here:\n",
    "\n",
    "- [Sonic The Hedgehog](http://store.steampowered.com/app/71113/Sonic_The_Hedgehog/)\n",
    "- [Sonic The Hedgehog 2](http://store.steampowered.com/app/71163/Sonic_The_Hedgehog_2/)\n",
    "- [Sonic 3 & Knuckles](http://store.steampowered.com/app/71162/Sonic_3___Knuckles/)\n",
    "\n",
    "In this notebook, we will show you how to use set up Gym-Retro on FloydHub.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Install Gym-Retro\n",
    "- Import and load the ROMs of the games\n",
    "- Use random-policy for a couple of steps\n",
    "- Visualize the agents\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- To execute a code cell, click on the cell and press `Shift + Enter` (shortcut for Run).\n",
    "- To learn more about Workspaces, check out the [Getting Started Notebook](./get_started_workspace.ipynb).\n",
    "- **Tip**: *Feel free to use this Notebook as a starting point for your own super awesome Reinforcement Learning task*.\n",
    "\n",
    "Now, let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "Before running the installation steps, we have to check the python version because `gym-retro` doesn't support Python 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your python version is OK.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Gym Retro requires Python 3.5 or 3.6.\")\n",
    "else:\n",
    "    print('Your python version is OK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: /tmp/tmp.WMyCzh6ubO/gpg.1.sh --keyserver\n",
      "keyserver.ubuntu.com\n",
      "--recv-keys\n",
      "6B05F25D762E3157\n",
      "gpg: requesting key 762E3157 from hkp server keyserver.ubuntu.com\n",
      "gpg: key DC282033: public key \"https://packagecloud.io/github/git-lfs (https://packagecloud.io/docs#gpg_signing) <support@packagecloud.io>\" imported\n",
      "gpg: Total number processed: 1\n",
      "gpg:               imported: 1  (RSA: 1)\n",
      "Installing deps...\n",
      "Get:1 http://storage.googleapis.com/bazel-apt stable InRelease [2464 B]\n",
      "Get:2 https://deb.nodesource.com/node_8.x xenial InRelease [4619 B]\n",
      "Get:3 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
      "Get:6 https://deb.nodesource.com/node_8.x xenial/main Sources [761 B]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release [564 B]\n",
      "Get:8 https://deb.nodesource.com/node_8.x xenial/main amd64 Packages [1005 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]\n",
      "Get:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release [564 B]\n",
      "Get:11 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial InRelease [23.8 kB]\n",
      "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg [801 B]\n",
      "Get:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release.gpg [833 B]\n",
      "Get:14 http://storage.googleapis.com/bazel-apt stable/jdk1.8 amd64 Packages [632 B]\n",
      "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages [209 kB]\n",
      "Get:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Packages [50.9 kB]\n",
      "Get:17 https://packagecloud.io/github/git-lfs/ubuntu xenial InRelease [23.2 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [908 kB]\n",
      "Get:19 https://packagecloud.io/github/git-lfs/ubuntu xenial/main amd64 Packages [7795 B]\n",
      "Get:20 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial/main amd64 Packages [3520 B]\n",
      "Get:21 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.7 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [575 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:24 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [6117 B]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages [1558 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu xenial/restricted amd64 Packages [14.1 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu xenial/universe amd64 Packages [9827 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu xenial/multiverse amd64 Packages [176 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [1304 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu xenial-updates/restricted amd64 Packages [13.1 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [983 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [19.1 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [7942 B]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [8532 B]\n",
      "Fetched 16.3 MB in 3s (4504 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "lua5.1 is already the newest version (5.1.5-8ubuntu1).\n",
      "libav-tools is already the newest version (7:2.8.15-0ubuntu0.16.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 177 not upgraded.\n",
      "- Done!\n"
     ]
    }
   ],
   "source": [
    "!bash apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6B05F25D762E3157\n",
    "!apt-get update && apt-get install -y lua5.1 libav-tools\n",
    "! bash install.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import retro\n",
    "import os\n",
    "\n",
    "from support import save_frames_as_gif, install_games_from_rom_dir, download_and_unzip_rom_archive_from_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and load external ROMs\n",
    "\n",
    "In the next Code Cells we will show how to load an external ROM from a dataset or downloaded from the internet. You haven't to worry about *filename or extension*, the `retro` package will perform hash matching to identify the games' ROMs.\n",
    "\n",
    "Please note that ROMs *are not included* and you must obtain them yourself. \n",
    "\n",
    "The following non-commerical ROMs are included with Gym Retro for testing purposes:\n",
    "\n",
    "- [Dekadrive](http://www.pouet.net/prod.php?which=67142) by Dekadence\n",
    "- [Automaton](https://pdroms.de/files/atari2600/automaton-minigame-compo-2003) by Derek Ledbetter\n",
    "- [Airstriker](https://pdroms.de/genesis/airstriker-v1-50-genesis-game) by Electrokinesis\n",
    "\n",
    "**WARNING**\n",
    "\n",
    "*Don't download or upload ROMs of games that you don't own, otherwise you are pirating *‚ò†Ô∏è!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available Games\n",
    "\n",
    "Let's check the games that can be imported by listing the available environments on `retro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(retro.data.list_games())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing ROMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Loading ROMs from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing SonicTheHedgehog2-Genesis\n",
      "Importing SonicAndKnuckles3-Genesis\n",
      "Imported 2 games\n"
     ]
    }
   ],
   "source": [
    "DS_PATH = 'roms/' # edit with your path/to/rom\n",
    "\n",
    "install_games_from_rom_dir(DS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Loading ROMs from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = '' # edit with your https://URL/of/your/ROM/zipfile\n",
    "\n",
    "download_and_unzip_rom_archive_from_url(URL, 'roms/')\n",
    "install_games_from_rom_dir('roms/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available Levels /States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get all the availables levels / states from the widget below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eab4f4ef33d4a52b6f27f879d93dacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='', description='GAME', placeholder='Type your GAME here'), Button(descri‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def get_available_state(GAME):\n",
    "    print('Available states for', GAME, 'game')\n",
    "    print('='*100)\n",
    "    if GAME in retro.data.list_games():\n",
    "\n",
    "        for state in retro.data.list_states(GAME):\n",
    "            print(state)\n",
    "\n",
    "    else:\n",
    "        print(\"No States available for\", GAME, \"- Please check if it's available in retro.list_games() list\")\n",
    "    \n",
    "\n",
    "interact_manual(get_available_state, GAME=widgets.Textarea(placeholder='Type your GAME here'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DNN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not running on floydhub with torch installed\n",
    "# !pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from collections import namedtuple\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, \n",
    "            #padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "            \n",
    "            \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 160, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(160, 80, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(80),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32000, 5000),\n",
    "            nn.Linear(5000, 1000),\n",
    "            nn.Linear(1000, 12))\n",
    "\n",
    "        # self.head = nn.Linear(12, 12) # 12 possible actions in sonic 2\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.to(device)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ''' This function for predicts classes by calculating the softmax '''\n",
    "        logits = self.forward(x)\n",
    "        # logits = F.softmax(logits)\n",
    "        indices = torch.argmax(logits, dim=1)\n",
    "        return indices.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use replay to handle image transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a screen, resize it etc. uses torchvision package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_to_plot):\n",
    "    \n",
    "    plt.figure()\n",
    "    if image_to_plot.ndim == 2:\n",
    "        plt.imshow(image_to_plot,cmap='gray', interpolation='none')\n",
    "    else:\n",
    "        plt.imshow(image_to_plot,interpolation='none') \n",
    "    plt.title(f'Example extracted screen, dimensions {image_to_plot.shape}.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Grayscale(),\n",
    "                    T.Resize((320,320)),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "# notes on output image dimensions/tensor layout\n",
    "# T.ToPILImage()\n",
    "#     Converts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape\n",
    "#     H x W x C to a PIL Image while preserving the value range.\n",
    "\n",
    "# env.render()\n",
    "#        - rgb_array: Return an numpy.ndarray with shape (x, y, 3),\n",
    "#          representing RGB values for an x-by-y pixel image, suitable\n",
    "#          for turning into a video.\n",
    "\n",
    "\n",
    "def get_screen():\n",
    "    '''\n",
    "    fetches a screen from the game, converts to greyscale and resizes to 320x320\n",
    "    '''\n",
    "    # return an nparray with order w,h,c\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    # plot_image(screen)\n",
    "    # optionally, reorder to h,w,c (i.e. rotate)\n",
    "    # screen = screen.transpose((1,0,2))\n",
    "    screen = resize(screen)\n",
    "    # plot_image(screen.cpu().numpy().squeeze())\n",
    "    \n",
    "    return screen.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    '''\n",
    "    selects an action for a given state, randomly choosing an action some proportion of the time\n",
    "    adapted from udacity\n",
    "    '''\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            #print(\"using net\")\n",
    "            # return policy_net(state).max(1)[1].view(1, 1)\n",
    "            return policy_net.predict(state)\n",
    "    else:\n",
    "        #print(\"random action\")\n",
    "        return torch.tensor([[random.randrange(12)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations():\n",
    "    '''\n",
    "    plot training and episode duration\n",
    "    from udacity\n",
    "    '''\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    '''\n",
    "    performs a backward pass\n",
    "    '''\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the main training loop in a definition\n",
    "\n",
    "frames = []\n",
    "\n",
    "def dqn_training(num_episodes, visualize_plt=False, max_steps=500, report_every=5000, display_action=False):\n",
    "    \"\"\"\n",
    "    num_episodes: int \n",
    "        number of episodes\n",
    "    visualize_plt: bool\n",
    "        if true, display the cartpole action in the notebook\n",
    "        if false (default), display the episodes x durations graph\n",
    "    \"\"\"\n",
    "    for i_episode in range(num_episodes):\n",
    "        # Initialize the environment and state\n",
    "        env.reset()        \n",
    "        last_screen = get_screen()\n",
    "        current_screen = get_screen()\n",
    "        state = current_screen - last_screen\n",
    "        iteration_counter = 0\n",
    "        for t in count():\n",
    "\n",
    "            # Select and perform an action\n",
    "            action = select_action(state)\n",
    "            if display_action:\n",
    "                print(\"action: \", action.squeeze())\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            #frames.append(observation) # collecting observation\n",
    "            \n",
    "            reward = torch.tensor([reward], device=device)\n",
    "\n",
    "            # Observe new state\n",
    "            last_screen = current_screen\n",
    "            current_screen = get_screen()\n",
    "            if not done:\n",
    "                next_state = current_screen - last_screen\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model()\n",
    "            if done or t>max_steps:\n",
    "                episode_durations.append(t + 1)\n",
    "                observation = env.reset()\n",
    "                #frames.append(observation)\n",
    "                #now = datetime.now() # current date and time\n",
    "                #date_time = now.strftime(\"%Y%d%Y-%H%M%S\")\n",
    "                #save_frames_as_gif(frames, filename=f'sonic2-{date_time}.gif')\n",
    "                break\n",
    "            iteration_counter += 1\n",
    "            if iteration_counter >= report_every:\n",
    "                now = datetime.now() # current date and time\n",
    "                date_time=now.strftime(\"%Y-%d-%Y %H:%M:%S\")\n",
    "                print(f\"t@{date_time}: {t+1}\")\n",
    "                #date_time = now.strftime(\"%Y%d%Y-%H%M%S\")\n",
    "                #save_frames_as_gif(frames, filename=f'sonic2-{date_time}.gif')\n",
    "                #frames.clear()\n",
    "                iteration_counter = 0\n",
    "        # Update the target network\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    #env.render(close=True)\n",
    "    env.close()\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "layer1.0.weight \t torch.Size([160, 1, 4, 4])\n",
      "layer1.0.bias \t torch.Size([160])\n",
      "layer1.1.weight \t torch.Size([160])\n",
      "layer1.1.bias \t torch.Size([160])\n",
      "layer1.1.running_mean \t torch.Size([160])\n",
      "layer1.1.running_var \t torch.Size([160])\n",
      "layer1.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.weight \t torch.Size([80, 160, 4, 4])\n",
      "layer2.0.bias \t torch.Size([80])\n",
      "layer2.1.weight \t torch.Size([80])\n",
      "layer2.1.bias \t torch.Size([80])\n",
      "layer2.1.running_mean \t torch.Size([80])\n",
      "layer2.1.running_var \t torch.Size([80])\n",
      "layer2.1.num_batches_tracked \t torch.Size([])\n",
      "fc1.0.weight \t torch.Size([5000, 32000])\n",
      "fc1.0.bias \t torch.Size([5000])\n",
      "fc1.1.weight \t torch.Size([1000, 5000])\n",
      "fc1.1.bias \t torch.Size([1000])\n",
      "fc1.2.weight \t torch.Size([12, 1000])\n",
      "fc1.2.bias \t torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# set to GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in policy_net.state_dict():\n",
    "    print(param_tensor, \"\\t\", policy_net.state_dict()[param_tensor].size())\n",
    "    \n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  tensor(11)\n",
      "action:  tensor(0)\n",
      "action:  tensor(2)\n",
      "action:  tensor(10)\n",
      "action:  tensor(3)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(4)\n",
      "action:  tensor(1)\n",
      "action:  tensor(4)\n",
      "action:  tensor(11)\n",
      "action:  tensor(7)\n",
      "action:  tensor(0)\n",
      "action:  tensor(4)\n",
      "action:  tensor(11)\n",
      "action:  tensor(11)\n",
      "action:  tensor(1)\n",
      "action:  tensor(9)\n",
      "action:  tensor(7)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(4)\n",
      "action:  tensor(5)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(11)\n",
      "action:  tensor(4)\n",
      "action:  tensor(0)\n",
      "action:  tensor(7)\n",
      "action:  tensor(3)\n",
      "action:  tensor(11)\n",
      "action:  tensor(10)\n",
      "action:  tensor(3)\n",
      "action:  tensor(11)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(9)\n",
      "action:  tensor(10)\n",
      "action:  tensor(5)\n",
      "action:  tensor(7)\n",
      "action:  tensor(5)\n",
      "action:  tensor(11)\n",
      "action:  tensor(3)\n",
      "t@2019-14-2019 05:05:06: 50\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(8)\n",
      "action:  tensor(9)\n",
      "action:  tensor(0)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(0)\n",
      "action:  tensor(10)\n",
      "action:  tensor(1)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(3)\n",
      "action:  tensor(3)\n",
      "action:  tensor(6)\n",
      "action:  tensor(8)\n",
      "action:  tensor(3)\n",
      "action:  tensor(2)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(3)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(0)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(11)\n",
      "action:  tensor(5)\n",
      "action:  tensor(7)\n",
      "action:  tensor(6)\n",
      "action:  tensor(0)\n",
      "action:  tensor(7)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(4)\n",
      "action:  tensor(8)\n",
      "action:  tensor(5)\n",
      "action:  tensor(5)\n",
      "action:  tensor(11)\n",
      "action:  tensor(3)\n",
      "action:  tensor(8)\n",
      "t@2019-14-2019 05:05:09: 100\n",
      "action:  tensor(8)\n",
      "action:  tensor(5)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(1)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(4)\n",
      "action:  tensor(0)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(10)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(2)\n",
      "action:  tensor(8)\n",
      "action:  tensor(11)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(0)\n",
      "action:  tensor(1)\n",
      "action:  tensor(7)\n",
      "action:  tensor(9)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(1)\n",
      "action:  tensor(9)\n",
      "action:  tensor(8)\n",
      "action:  tensor(11)\n",
      "action:  tensor(11)\n",
      "action:  tensor(4)\n",
      "action:  tensor(1)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(8)\n",
      "action:  tensor(5)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "action:  tensor(10)\n",
      "action:  tensor(9)\n",
      "t@2019-14-2019 05:05:14: 150\n",
      "action:  tensor(2)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(10)\n",
      "action:  tensor(4)\n",
      "action:  tensor(11)\n",
      "action:  tensor(11)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(5)\n",
      "action:  tensor(6)\n",
      "action:  tensor(7)\n",
      "action:  tensor(0)\n",
      "action:  tensor(3)\n",
      "action:  tensor(5)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(5)\n",
      "action:  tensor(11)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(0)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(5)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(7)\n",
      "action:  tensor(9)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "t@2019-14-2019 05:05:19: 200\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(11)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "action:  tensor(5)\n",
      "action:  tensor(1)\n",
      "action:  tensor(2)\n",
      "action:  tensor(4)\n",
      "action:  tensor(2)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(1)\n",
      "action:  tensor(7)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(0)\n",
      "action:  tensor(4)\n",
      "action:  tensor(11)\n",
      "action:  tensor(7)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(11)\n",
      "action:  tensor(9)\n",
      "action:  tensor(1)\n",
      "action:  tensor(7)\n",
      "action:  tensor(1)\n",
      "action:  tensor(4)\n",
      "action:  tensor(5)\n",
      "action:  tensor(6)\n",
      "action:  tensor(0)\n",
      "action:  tensor(1)\n",
      "action:  tensor(11)\n",
      "action:  tensor(1)\n",
      "action:  tensor(8)\n",
      "action:  tensor(5)\n",
      "action:  tensor(1)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(7)\n",
      "action:  tensor(2)\n",
      "t@2019-14-2019 05:05:24: 250\n",
      "action:  tensor(1)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(7)\n",
      "action:  tensor(0)\n",
      "action:  tensor(5)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(8)\n",
      "action:  tensor(3)\n",
      "action:  tensor(11)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(1)\n",
      "action:  tensor(8)\n",
      "action:  tensor(1)\n",
      "action:  tensor(8)\n",
      "action:  tensor(1)\n",
      "action:  tensor(11)\n",
      "action:  tensor(10)\n",
      "action:  tensor(8)\n",
      "action:  tensor(10)\n",
      "action:  tensor(5)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(2)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(2)\n",
      "action:  tensor(1)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "t@2019-14-2019 05:05:30: 300\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(8)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(1)\n",
      "action:  tensor(0)\n",
      "action:  tensor(0)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(5)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(8)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(7)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(0)\n",
      "action:  tensor(7)\n",
      "action:  tensor(10)\n",
      "action:  tensor(5)\n",
      "action:  tensor(4)\n",
      "action:  tensor(5)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(8)\n",
      "action:  tensor(4)\n",
      "action:  tensor(10)\n",
      "action:  tensor(3)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(11)\n",
      "action:  tensor(1)\n",
      "action:  tensor(6)\n",
      "t@2019-14-2019 05:05:35: 350\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(0)\n",
      "action:  tensor(8)\n",
      "action:  tensor(4)\n",
      "action:  tensor(8)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(0)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "action:  tensor(10)\n",
      "action:  tensor(6)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(11)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(5)\n",
      "action:  tensor(11)\n",
      "action:  tensor(11)\n",
      "action:  tensor(6)\n",
      "action:  tensor(10)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(6)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "action:  tensor(7)\n",
      "t@2019-14-2019 05:05:41: 400\n",
      "action:  tensor(4)\n",
      "action:  tensor(0)\n",
      "action:  tensor(11)\n",
      "action:  tensor(5)\n",
      "action:  tensor(6)\n",
      "action:  tensor(1)\n",
      "action:  tensor(6)\n",
      "action:  tensor(9)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(8)\n",
      "action:  tensor(0)\n",
      "action:  tensor(3)\n",
      "action:  tensor(6)\n",
      "action:  tensor(7)\n",
      "action:  tensor(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(2)\n",
      "action:  tensor(4)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(8)\n",
      "action:  tensor(11)\n",
      "action:  tensor(9)\n",
      "action:  tensor(5)\n",
      "action:  tensor(0)\n",
      "action:  tensor(5)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(1)\n",
      "action:  tensor(6)\n",
      "action:  tensor(7)\n",
      "action:  tensor(9)\n",
      "action:  tensor(5)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(8)\n",
      "action:  tensor(2)\n",
      "action:  tensor(9)\n",
      "action:  tensor(5)\n",
      "action:  tensor(9)\n",
      "action:  tensor(9)\n",
      "action:  tensor(8)\n",
      "action:  tensor(1)\n",
      "action:  tensor(1)\n",
      "action:  tensor(8)\n",
      "action:  tensor(5)\n",
      "action:  tensor(11)\n",
      "t@2019-14-2019 05:05:46: 450\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(3)\n",
      "action:  tensor(7)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(1)\n",
      "action:  tensor(4)\n",
      "action:  tensor(11)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(0)\n",
      "action:  tensor(10)\n",
      "action:  tensor(8)\n",
      "action:  tensor(0)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(1)\n",
      "action:  tensor(8)\n",
      "action:  tensor(7)\n",
      "action:  tensor(6)\n",
      "action:  tensor(2)\n",
      "action:  tensor(11)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(8)\n",
      "action:  tensor(6)\n",
      "action:  tensor(0)\n",
      "action:  tensor(11)\n",
      "action:  tensor(6)\n",
      "action:  tensor(5)\n",
      "action:  tensor(4)\n",
      "action:  tensor(6)\n",
      "action:  tensor(6)\n",
      "action:  tensor(11)\n",
      "action:  tensor(4)\n",
      "action:  tensor(4)\n",
      "action:  tensor(3)\n",
      "action:  tensor(3)\n",
      "action:  tensor(6)\n",
      "action:  tensor(4)\n",
      "action:  tensor(7)\n",
      "action:  tensor(6)\n",
      "action:  tensor(3)\n",
      "action:  tensor(7)\n",
      "action:  tensor(6)\n",
      "t@2019-14-2019 05:05:53: 500\n",
      "action:  tensor(8)\n",
      "action:  tensor(9)\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# close current environment if there is one (e.g. on failure to complete last time)\n",
    "try:\n",
    "    env.close()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# create the environment\n",
    "# Loading the level\n",
    "env = retro.make(\n",
    "    game='SonicTheHedgehog2-Genesis',  # Game\n",
    "    state='MetropolisZone.Act1.state',  # Level / State\n",
    "    record=True)  # Record the Run\n",
    "\n",
    "num_episodes=1\n",
    "max_steps = 500\n",
    "report_every = max_steps/10\n",
    "display_action=True\n",
    "dqn_training(num_episodes, max_steps=max_steps, report_every=report_every, display_action=display_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "# save models\n",
    "print('saving')\n",
    "date_time = datetime.now().strftime(\"%Y%d%Y-%H%M%S\")\n",
    "torch.save(target_net.state_dict(), f'models/target_net-{date_time}.pt')\n",
    "torch.save(policy_net.state_dict(), f'models/policy_net-{date_time}.pt')\n",
    "print('saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(policy_net.fc1.state_dict(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-5318a4eea95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bias' is not defined"
     ]
    }
   ],
   "source": [
    "print(policy_net.layer1.state_dict(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next steps will load the `MetropolisZone` level from **SonicTheHedgehog2** game and make a random walk in the environment for 300 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the level\n",
    "env = retro.make(\n",
    "    game='SonicTheHedgehog2-Genesis',  # Game\n",
    "    state='MetropolisZone.Act1.state',  # Level / State\n",
    "    record=True)  # Record the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiBinary(12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frame list collector\n",
    "frames = []\n",
    "STEPS = 300\n",
    "\n",
    "observation = env.reset()\n",
    "for i in range(STEPS): # Take random actions for # STEPS\n",
    "    random_action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step( random_action )\n",
    "    frames.append(observation) # collecting observation\n",
    "    \n",
    "    if done: # If the env is done make sure you reset it\n",
    "        observation = env.reset()\n",
    "        frames.append(observation)\n",
    "        \n",
    "# Save the run\n",
    "save_frames_as_gif(frames, filename='sonic2-metropolis-act1-300-steps.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results\n",
    "\n",
    "You can now visualize the run by opening the gif file from the `File Tab Viewer` at the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visual](https://github.com/floydhub/gym-retro-template/raw/master/images/visual.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's your turn\n",
    "\n",
    "#### Baseline\n",
    "OpenAI provides usefull baseline implementations that you can tweak in the [retro-baselines](https://github.com/openai/retro-baselines) repo on GitHub. You can use these as starting points for making fancier algorithms or just for tweaking parameters on the existing ones.\n",
    "\n",
    "#### Running Multiple Gym-Retro Environments\n",
    "This environment comes with the `retrowrapper` installed, in this way you can [run multiple Gym-Retro Environments](https://mikelyons.org/2018/05/22/Multiple-Retro-Environments.html). To use it, just instantiate it like you would a normal retro environment, and then treat it exactly the same, but now you can have multiples in a single python process. Magic! For more see the [repo](https://github.com/MaxStrange/retrowrapper). \n",
    "\n",
    "```\n",
    "import retrowrapper\n",
    "\n",
    "env1 = retrowrapper.RetroWrapper(\n",
    "    game='SonicTheHedgehog2-Genesis',\n",
    "    state='MetropolisZone.Act1' \n",
    ")\n",
    "env2 = retrowrapper.RetroWrapper( \n",
    "    game='SonicTheHedgehog2-Genesis', \n",
    "    state='MetropolisZone.Act2' \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### That's all folks - don't forget to shutdown your workspace once you're done üôÇ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
